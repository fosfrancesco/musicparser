{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/home/francesco/miniconda3/envs/musicparser/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from musicparser.data_loading import JTBDataset\n",
    "import wandb\n",
    "from musicparser.data_loading import JTBDataModule\n",
    "from musicparser.models import ArcPredictionLightModel\n",
    "from musicparser.postprocessing import eisner_fast, eisner_slow\n",
    "from pytorch_lightning import Trainer\n",
    "import os\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading open tree data...\n",
      "Done loading data. 0 out of 150 pieces were discarded because of errors.\n"
     ]
    }
   ],
   "source": [
    "dataset = JTBDataset(\"data/jazz_tb/treebank.json\", data_augmentation=\"preprocess\", only_tree=True, tree_type=\"open\",n_jobs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Blue In Green'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.titles[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.chords_features[8].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = wandb.init()\n",
    "# artifact = run.use_artifact('fosfrancesco/loo_JTB/model-go1417zv:v0', type='model')\n",
    "# artifact_dir = artifact.download()\n",
    "\n",
    "artifact_dir = \"artifacts/model-go1417zv:v0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading complete tree data...\n",
      "Done loading data. 0 out of 150 pieces were discarded because of errors.\n",
      "Augmenting data...\n",
      "Augmenting data...\n",
      "Train size :1788, Val size :1, Test size :1\n",
      "No pretraining data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "/share/home/francesco/miniconda3/envs/musicparser/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: PossibleUserWarning: The dataloader, predict_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 40 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "datamodule = JTBDataModule(batch_size=1, num_workers=1, data_augmentation=\"preprocess\", only_tree=True, loo_index=8)\n",
    "datamodule.setup()\n",
    "model = ArcPredictionLightModel.load_from_checkpoint(checkpoint_path=os.path.join(os.path.normpath(artifact_dir), \"model.ckpt\"))\n",
    "\n",
    "wandb_logger = True\n",
    "\n",
    "trainer = Trainer(\n",
    "    max_epochs=60, accelerator=\"auto\", devices= [0], #strategy=\"ddp\",\n",
    "    num_sanity_val_steps=1,\n",
    "    logger=wandb_logger,\n",
    "    deterministic=True\n",
    "    )\n",
    "\n",
    "# trainer.tune(model, datamodule=datamodule)\n",
    "# print(\"LR set to\", model.lr)\n",
    "out_dict= trainer.predict(model, dataloaders=datamodule.test_dataloader())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " [[[[[[[[1, 2], 3], 4], 5], 6], 7], 8], [[[9, 10], 11], [12, [13, [14, 15]]]]]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict[\"pred_ctree\"].unlabeled_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[[[0, 1], 2], [[[[[3, 4], 5], 6], 7], 8]], [[9, 10], 11]],\n",
       " [[12, 13], [14, 15]]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict[\"truth_ctree\"].unlabeled_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1,  1,  2,  8,  4,  5,  6,  7,  8, 11, 10, 11, 15, 13, 15, 15, -1])\n"
     ]
    }
   ],
   "source": [
    "# print(out_dict[\"head_seq\"] -1)\n",
    "# print(out_dict[\"head_seq_postp\"] -1)\n",
    "print(out_dict[\"head_seq_truth\"] -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  0,  3,  4,  5,  6,  7,  8,  9, 16, 11, 12, 16, 16, 16, 16,  1])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dict[\"head_seq_postp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([240, 2])\n",
      "torch.Size([240])\n"
     ]
    }
   ],
   "source": [
    "# out_dict = out_dict[0]\n",
    "pot_arcs = out_dict[\"pot_arcs\"]\n",
    "print(pot_arcs.shape)\n",
    "arc_pred__mask_normalized = out_dict[\"arc_pred__mask_normalized\"]\n",
    "print(arc_pred__mask_normalized.shape)\n",
    "num_notes = 16\n",
    "\n",
    "adj1, pred_arc1 = model.postprocess(pot_arcs, arc_pred__mask_normalized, num_notes, alg = \"eisner\")\n",
    "adj2, pred_arc2 = model.postprocess(pot_arcs, arc_pred__mask_normalized, num_notes, alg = \"chuliu_edmonds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 1], [3, 2], [4, 3], [5, 4], [6, 5], [7, 6], [8, 7], [15, 8], [10, 9], [11, 10], [15, 11], [15, 12], [15, 13], [15, 14], [0, 15]]\n",
      "[[2, 0], [2, 1], [3, 2], [4, 3], [5, 4], [6, 5], [7, 6], [8, 7], [9, 8], [11, 10], [15, 11], [15, 12], [15, 13], [15, 14], [8, 15]]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(pred_arc1, key=lambda x: x[1]))\n",
    "print(sorted(pred_arc2, key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_local(pot_arcs, arc_pred__mask_normalized, num_notes, alg = \"eisner\"):\n",
    "    adj_pred_probs = torch.sparse_coo_tensor(pot_arcs.T, arc_pred__mask_normalized, (num_notes, num_notes)).to_dense().to(arc_pred__mask_normalized.device)\n",
    "    # add a new upper row and left column for the root to the adjency matrix\n",
    "    adj_pred_probs_root = torch.vstack((torch.zeros((1, num_notes),device = arc_pred__mask_normalized.device), adj_pred_probs))\n",
    "    adj_pred_probs_root = torch.hstack((torch.zeros((num_notes+1, 1),device = arc_pred__mask_normalized.device), adj_pred_probs_root))\n",
    "    # take log probs\n",
    "    adj_pred_log_probs_root = torch.log(adj_pred_probs_root)\n",
    "    # postprocess with chu-liu edmonds algorithm\n",
    "    # if alg == \"chuliu_edmonds\": #transpose to have an adjency matrix with edges pointing toward the parent node and \n",
    "    #     head_seq = chuliu_edmonds_one_root(adj_pred_log_probs_root.cpu().numpy().T)\n",
    "    # elif alg == \"eisner\":\n",
    "    #     head_seq = eisner(adj_pred_log_probs_root.cpu().numpy())\n",
    "    if alg == \"eisner_fast\":\n",
    "        head_seq = eisner_fast(torch.unsqueeze(adj_pred_log_probs_root,dim=0).cpu(), torch.ones(1,num_notes).long())\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"alg must be either eisner or chuliu_edmonds\")\n",
    "    head_seq = head_seq[1:] # remove the root\n",
    "    # structure the postprocess results in an adjency matrix with edges that point toward the child node. Also predict the list of d_arcs\n",
    "    adj_pred_postp = torch.zeros((num_notes,num_notes))\n",
    "    pred_arc_postp = []\n",
    "    for i, head in enumerate(head_seq):\n",
    "        if head != 0:\n",
    "            # id is index in note list + 1\n",
    "            adj_pred_postp[head-1, i] = 1\n",
    "            pred_arc_postp.append([head-1, i])\n",
    "        else: #handle the root\n",
    "            root = i\n",
    "    return adj_pred_postp, pred_arc_postp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# postprocess_local(torch.tensor(pot_arcs).clone(), torch.tensor(arc_pred__mask_normalized).clone(), num_notes, alg = \"eisner_slow\")\n",
    "adj3, pred_arc3 = postprocess_local(pot_arcs,arc_pred__mask_normalized, num_notes, alg = \"eisner_slow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "         True, True, True, True]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj3 == adj1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "[ 0.  2.  3.  4.  5.  6.  7.  8. 15. 10. 11. 15. 15. 15. 15.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(num_notes)\n",
    "head_seq3 = np.zeros(num_notes)\n",
    "for arc in pred_arc3:\n",
    "    head_seq3[arc[1]] = arc[0]\n",
    "\n",
    "print(head_seq3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 1], [3, 2], [4, 3], [5, 4], [6, 5], [7, 6], [8, 7], [15, 8], [10, 9], [11, 10], [15, 11], [15, 12], [15, 13], [15, 14], [0, 15]]\n",
      "[[2, 0], [2, 1], [3, 2], [4, 3], [5, 4], [6, 5], [7, 6], [8, 7], [9, 8], [11, 10], [15, 11], [15, 12], [15, 13], [15, 14], [8, 15]]\n",
      "[[2, 1], [3, 2], [4, 3], [5, 4], [6, 5], [7, 6], [8, 7], [15, 8], [10, 9], [11, 10], [15, 11], [15, 12], [15, 13], [15, 14], [0, 15]]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(pred_arc1, key=lambda x: x[1]))\n",
    "print(sorted(pred_arc2, key=lambda x: x[1]))\n",
    "print(sorted(pred_arc3, key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1,  0,  2,  3,  4,  5,  6,  7,  8, 15, 10, 11, 15, 12, 15, 15, 15])\n",
      "tensor([-1, -1,  2,  3,  4,  5,  6,  7,  8, 15, 10, 11, 15, 15, 15, 15,  0])\n"
     ]
    }
   ],
   "source": [
    "print(out_dict[\"head_seq\"] -1)\n",
    "print(out_dict[\"head_seq_postp\"] -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 16])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0,  0,  3,  4,  5,  6,  7,  8,  9, 16, 11, 12, 16, 16, 16, 16,  1]) 17\n",
      "[ 0.  2.  3.  4.  5.  6.  7.  8. 15. 10. 11. 15. 15. 15. 15.  0.] 16\n",
      "tensor([ 0,  2,  3,  9,  5,  6,  7,  8,  9, 12, 11, 12, 16, 14, 16, 16,  0]) 16\n",
      "0\n",
      "16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/data/tmp/francesco/ipykernel_28525/3098414528.py:16: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n",
      "  print(np.sum(np.array(out_dict[\"head_seq_truth\"])==np.array(head_seq3)))\n"
     ]
    }
   ],
   "source": [
    "head_adj = adj3.T #now each row contains the probabilities for the heads of the corresponding note\n",
    "# print(head_adj)\n",
    "# print(np.argmax(head_adj,axis = 1))\n",
    "# add a new upper row and left column for the root to the adjency matrix\n",
    "head_adj_root = torch.vstack((torch.zeros((1, num_notes),device = head_adj.device), head_adj))\n",
    "# print(head_adj_root)\n",
    "head_adj_root = torch.hstack((torch.zeros((num_notes+1, 1),device = head_adj_root.device), head_adj_root))\n",
    "# print(head_adj_root)\n",
    "head_adj_root[0][0] = 1\n",
    "# print(head_adj_root)\n",
    "\n",
    "print(np.argmax(head_adj_root, axis = 1), len(np.argmax(head_adj_root,axis = 1)))\n",
    "print(head_seq3, len(head_seq3))\n",
    "print(out_dict[\"head_seq_truth\"], len(head_seq_truth))\n",
    "\n",
    "print(np.sum(np.array(out_dict[\"head_seq_truth\"])==np.array(head_seq3)))\n",
    "\n",
    "# print(np.sum(out_dict[\"head_seq_truth\"]==np.argmax(head_adj_root, axis = 1)))\n",
    "# np.sum(out_dict[\"head_seq_truth\"]==np.argmax(head_adj_root, axis = 1))\n",
    "\n",
    "\n",
    "print(num_notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 16]) torch.Size([17, 17])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_pred_probs_root_postp = model.compute_head_probs_root_from_adj(adj, 16)\n",
    "print(adj.shape,adj_pred_probs_root_postp.shape)\n",
    "adj_pred_probs_root_postp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "musicparser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
